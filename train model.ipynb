{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"NL7-NCiQCciY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713354347638,"user_tz":-210,"elapsed":25169,"user":{"displayName":"mehdi dehghani","userId":"16329055276283908551"}},"outputId":"a837fab3-5e3b-4559-cbc8-c33ea3c7acf7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"38QXLP29hfY9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713354347639,"user_tz":-210,"elapsed":14,"user":{"displayName":"mehdi dehghani","userId":"16329055276283908551"}},"outputId":"cc3ad884-0d6e-4b81-ceb4-98d2ea1d7796"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation\n"]}],"source":["%cd /content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation\n","#%cd /content/drive/MyDrive/diffusion/generative-inverse-heat-dissipation"]},{"cell_type":"code","source":["#!pip install mpi4py"],"metadata":{"id":"sPPG6D7i_-Gf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from mpi4py import MPI\n","# shard=MPI.COMM_WORLD.Get_rank(),\n","# num_shards=MPI.COMM_WORLD.Get_size(),\n","# print('shard',shard)  #(0,)\n","# print('num_shards',num_shards) #(1,)"],"metadata":{"id":"R4EfTJeq-Zsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip install -r requirements.txt"],"metadata":{"id":"FQEs_GBOPmV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q blobfile\n","!pip install -q ml_collections"],"metadata":{"id":"p0rw8FgYLsO3","executionInfo":{"status":"ok","timestamp":1713272059771,"user_tz":-210,"elapsed":14274,"user":{"displayName":"mehdi dehghani","userId":"16329055276283908551"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aa5a299e-a0df-4a12-8c44-36df2ec9ba2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ml_collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KQPLbzPfBsGR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train Mnist"],"metadata":{"id":"JeSettkyL7op"}},{"cell_type":"code","source":["# train model with mnist dataset\n","# bluring method : dctblur\n","# end iter : 0\n","!python train.py --config configs/mnist/default_mnist_configs.py --blur_type dctblur --workdir ./runs/mnist/dctblur"],"metadata":{"id":"lBZ4uicxOg01"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5EK_J6sx0gD"},"outputs":[],"source":["# train model with mnist dataset\n","# bluring method : fftblur\n","# end iter : 7000\n","!python train.py --config configs/mnist/default_mnist_configs.py --blur_type fftblur --workdir ./runs/mnist/fftblur"]},{"cell_type":"markdown","source":["# Train Cifar10"],"metadata":{"id":"q9-Df3niMCYu"}},{"cell_type":"code","source":["# train model with cifar10 dataset\n","# bluring method : dctblur\n","# end iter : 24000\n","!python train.py --config configs/cifar10/default_cifar10_configs.py --blur_type dctblur --workdir ./runs/cifar/dctblur"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGtxgVwcOk6P","executionInfo":{"status":"ok","timestamp":1711364900888,"user_tz":-210,"elapsed":845593,"user":{"displayName":"mehdi dehghani","userId":"16329055276283908551"}},"outputId":"ce4e2c1b-f653-48f6-9c93-aa0ec6e8310b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-25 10:53:41.846037: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-25 10:53:41.846107: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-25 10:53:41.847513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-25 10:53:42.940938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","initial_step: 23501\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Files already downloaded and verified\n","Files already downloaded and verified\n","I0325 10:55:00.967066 132025781187200 train.py:112] Starting training loop at step 23501.\n","I0325 10:55:00.967652 132025781187200 train.py:113] Running on cuda:0\n","I0325 10:56:24.804996 132025781187200 train.py:136] Starting evaluation\n","I0325 10:56:48.712039 132025781187200 train.py:147] step: 23600, eval_loss: 2.89330e-02\n","I0325 10:58:12.602219 132025781187200 train.py:136] Starting evaluation\n","I0325 10:58:35.959683 132025781187200 train.py:147] step: 23700, eval_loss: 2.70461e-02\n","I0325 11:00:00.207803 132025781187200 train.py:136] Starting evaluation\n","I0325 11:00:23.723319 132025781187200 train.py:147] step: 23800, eval_loss: 2.77469e-02\n","I0325 11:01:48.309417 132025781187200 train.py:136] Starting evaluation\n","I0325 11:02:11.642630 132025781187200 train.py:147] step: 23900, eval_loss: 2.70844e-02\n","I0325 11:03:35.979672 132025781187200 train.py:131] Saving temporary checkpoint\n","I0325 11:03:42.479785 132025781187200 train.py:136] Starting evaluation\n","I0325 11:04:06.350151 132025781187200 train.py:147] step: 24000, eval_loss: 2.32338e-02\n","I0325 11:04:06.350625 132025781187200 train.py:159] Sampling...\n","I0325 11:07:02.359707 132025781187200 train.py:136] Starting evaluation\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/train.py\", line 175, in <module>\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/train.py\", line 31, in main\n","    train(FLAGS.config, FLAGS.workdir,FLAGS.blur_type)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/train.py\", line 145, in train\n","    eval_loss, losses_batch, fwd_steps_batch = eval_step_fn(state, eval_batch)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/scripts/losses.py\", line 129, in step_fn\n","    loss, losses_batch, fwd_steps_batch = loss_fn(model, batch)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/scripts/losses.py\", line 74, in loss_fn\n","    diff = model_fn(perturbed_data, fwd_steps)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/model_code/utils.py\", line 239, in model_fn\n","    return model(x, fwd_steps)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py\", line 183, in forward\n","    return self.module(*inputs[0], **module_kwargs[0])\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/model_code/unet.py\", line 661, in forward\n","    h = th.cat([h, hs.pop()], dim=1)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHCUvSi4ac53"},"outputs":[],"source":["# train model with cifar10 dataset\n","# bluring method : fftblur\n","# end iter : 24000\n","!python train.py --config configs/cifar10/default_cifar10_configs.py --blur_type fftblur --workdir ./runs/cifar/fftblur"]},{"cell_type":"code","source":["# train model with cifar10 dataset\n","# bluring method : fftblur\n","# end iter : 24000\n","!python train.py --config configs/cifar10/default_cifar10_configs.py --blur_type fftblur --workdir ./runs/cifar/fftblur_scale"],"metadata":{"id":"WHiNeQ0ozABi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2b9caed-9a8e-4e6a-fe65-d49e8bb0824e","executionInfo":{"status":"ok","timestamp":1712815139537,"user_tz":-210,"elapsed":13712191,"user":{"displayName":"Mehdi “Dehghani”","userId":"11956428046354443444"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-11 02:09:19.013692: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-11 02:09:19.013770: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-11 02:09:19.015239: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-11 02:09:20.264089: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","initial_step: 12001\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Files already downloaded and verified\n","Files already downloaded and verified\n","I0411 02:10:13.583678 136209604935680 train.py:114] Starting training loop at step 12001.\n","I0411 02:10:13.584411 136209604935680 train.py:115] Running on cuda:0\n","I0411 02:11:33.532630 136209604935680 train.py:138] Starting evaluation\n","I0411 02:11:56.327072 136209604935680 train.py:149] step: 12100, eval_loss: 3.11117e-02\n","I0411 02:13:16.433800 136209604935680 train.py:138] Starting evaluation\n","I0411 02:13:38.420394 136209604935680 train.py:149] step: 12200, eval_loss: 3.51957e-02\n","I0411 02:14:58.446655 136209604935680 train.py:138] Starting evaluation\n","I0411 02:15:20.575483 136209604935680 train.py:149] step: 12300, eval_loss: 3.29760e-02\n","I0411 02:16:41.241795 136209604935680 train.py:138] Starting evaluation\n","I0411 02:17:03.091926 136209604935680 train.py:149] step: 12400, eval_loss: 3.42176e-02\n","I0411 02:18:23.177957 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 02:18:29.036190 136209604935680 train.py:138] Starting evaluation\n","I0411 02:18:51.233106 136209604935680 train.py:149] step: 12500, eval_loss: 3.70731e-02\n","I0411 02:20:11.232950 136209604935680 train.py:138] Starting evaluation\n","I0411 02:20:33.336842 136209604935680 train.py:149] step: 12600, eval_loss: 3.35119e-02\n","I0411 02:21:53.437784 136209604935680 train.py:138] Starting evaluation\n","I0411 02:22:15.784110 136209604935680 train.py:149] step: 12700, eval_loss: 3.49504e-02\n","I0411 02:23:36.291740 136209604935680 train.py:138] Starting evaluation\n","I0411 02:23:57.738328 136209604935680 train.py:149] step: 12800, eval_loss: 4.21467e-02\n","I0411 02:25:18.234297 136209604935680 train.py:138] Starting evaluation\n","I0411 02:25:41.066438 136209604935680 train.py:149] step: 12900, eval_loss: 3.61947e-02\n","I0411 02:27:01.139929 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 02:27:08.560986 136209604935680 train.py:138] Starting evaluation\n","I0411 02:27:30.887881 136209604935680 train.py:149] step: 13000, eval_loss: 3.68551e-02\n","I0411 02:27:30.888471 136209604935680 train.py:161] Sampling...\n","I0411 02:30:16.845385 136209604935680 train.py:138] Starting evaluation\n","I0411 02:30:38.938909 136209604935680 train.py:149] step: 13100, eval_loss: 3.17159e-02\n","I0411 02:31:59.192483 136209604935680 train.py:138] Starting evaluation\n","I0411 02:32:21.177254 136209604935680 train.py:149] step: 13200, eval_loss: 3.37109e-02\n","I0411 02:33:41.275243 136209604935680 train.py:138] Starting evaluation\n","I0411 02:34:03.707855 136209604935680 train.py:149] step: 13300, eval_loss: 3.59489e-02\n","I0411 02:35:23.795751 136209604935680 train.py:138] Starting evaluation\n","I0411 02:35:45.904672 136209604935680 train.py:149] step: 13400, eval_loss: 3.19544e-02\n","I0411 02:37:06.029174 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 02:37:13.598141 136209604935680 train.py:138] Starting evaluation\n","I0411 02:37:36.857998 136209604935680 train.py:149] step: 13500, eval_loss: 3.59426e-02\n","I0411 02:38:57.605791 136209604935680 train.py:138] Starting evaluation\n","I0411 02:39:19.021450 136209604935680 train.py:149] step: 13600, eval_loss: 5.59654e-02\n","I0411 02:40:39.034752 136209604935680 train.py:138] Starting evaluation\n","I0411 02:41:01.673359 136209604935680 train.py:149] step: 13700, eval_loss: 2.79919e-02\n","I0411 02:42:21.736294 136209604935680 train.py:138] Starting evaluation\n","I0411 02:42:44.085413 136209604935680 train.py:149] step: 13800, eval_loss: 3.15995e-02\n","I0411 02:44:04.255924 136209604935680 train.py:138] Starting evaluation\n","I0411 02:44:26.396486 136209604935680 train.py:149] step: 13900, eval_loss: 3.27557e-02\n","I0411 02:45:46.685975 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 02:45:50.593746 136209604935680 train.py:138] Starting evaluation\n","I0411 02:46:12.664587 136209604935680 train.py:149] step: 14000, eval_loss: 2.87857e-02\n","I0411 02:46:12.665303 136209604935680 train.py:161] Sampling...\n","I0411 02:48:58.638131 136209604935680 train.py:138] Starting evaluation\n","I0411 02:49:20.612042 136209604935680 train.py:149] step: 14100, eval_loss: 3.63479e-02\n","I0411 02:50:41.234609 136209604935680 train.py:138] Starting evaluation\n","I0411 02:51:03.437569 136209604935680 train.py:149] step: 14200, eval_loss: 3.37222e-02\n","I0411 02:52:23.662706 136209604935680 train.py:138] Starting evaluation\n","I0411 02:52:45.658096 136209604935680 train.py:149] step: 14300, eval_loss: 3.33605e-02\n","I0411 02:54:06.392728 136209604935680 train.py:138] Starting evaluation\n","I0411 02:54:27.729969 136209604935680 train.py:149] step: 14400, eval_loss: 2.62305e-02\n","I0411 02:55:47.894221 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 02:55:56.000401 136209604935680 train.py:138] Starting evaluation\n","I0411 02:56:19.133462 136209604935680 train.py:149] step: 14500, eval_loss: 3.23876e-02\n","I0411 02:57:39.452271 136209604935680 train.py:138] Starting evaluation\n","I0411 02:58:01.357306 136209604935680 train.py:149] step: 14600, eval_loss: 3.45766e-02\n","I0411 02:59:21.661548 136209604935680 train.py:138] Starting evaluation\n","I0411 02:59:43.736006 136209604935680 train.py:149] step: 14700, eval_loss: 2.72256e-02\n","I0411 03:01:04.411356 136209604935680 train.py:138] Starting evaluation\n","I0411 03:01:26.457314 136209604935680 train.py:149] step: 14800, eval_loss: 3.41317e-02\n","I0411 03:02:46.959819 136209604935680 train.py:138] Starting evaluation\n","I0411 03:03:08.991521 136209604935680 train.py:149] step: 14900, eval_loss: 3.33221e-02\n","I0411 03:04:29.442469 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 03:04:37.398165 136209604935680 train.py:138] Starting evaluation\n","I0411 03:04:59.698492 136209604935680 train.py:149] step: 15000, eval_loss: 3.49352e-02\n","I0411 03:04:59.698801 136209604935680 train.py:161] Sampling...\n","I0411 03:07:45.875953 136209604935680 train.py:138] Starting evaluation\n","I0411 03:08:08.359381 136209604935680 train.py:149] step: 15100, eval_loss: 3.28405e-02\n","I0411 03:09:28.851499 136209604935680 train.py:138] Starting evaluation\n","I0411 03:09:50.209382 136209604935680 train.py:149] step: 15200, eval_loss: 3.81329e-02\n","I0411 03:11:10.526085 136209604935680 train.py:138] Starting evaluation\n","I0411 03:11:33.360480 136209604935680 train.py:149] step: 15300, eval_loss: 3.31121e-02\n","I0411 03:12:53.835948 136209604935680 train.py:138] Starting evaluation\n","I0411 03:13:15.878266 136209604935680 train.py:149] step: 15400, eval_loss: 2.88288e-02\n","I0411 03:14:36.249186 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 03:14:40.237097 136209604935680 train.py:138] Starting evaluation\n","I0411 03:15:02.542221 136209604935680 train.py:149] step: 15500, eval_loss: 3.55680e-02\n","I0411 03:16:22.881339 136209604935680 train.py:138] Starting evaluation\n","I0411 03:16:44.863763 136209604935680 train.py:149] step: 15600, eval_loss: 3.74452e-02\n","I0411 03:18:05.360003 136209604935680 train.py:138] Starting evaluation\n","I0411 03:18:27.837404 136209604935680 train.py:149] step: 15700, eval_loss: 3.44243e-02\n","I0411 03:19:47.978646 136209604935680 train.py:138] Starting evaluation\n","I0411 03:20:10.070109 136209604935680 train.py:149] step: 15800, eval_loss: 2.95625e-02\n","I0411 03:21:30.362066 136209604935680 train.py:138] Starting evaluation\n","I0411 03:21:52.385870 136209604935680 train.py:149] step: 15900, eval_loss: 3.34270e-02\n","I0411 03:23:13.168474 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 03:23:17.268625 136209604935680 train.py:138] Starting evaluation\n","I0411 03:23:38.774292 136209604935680 train.py:149] step: 16000, eval_loss: 4.41333e-02\n","I0411 03:23:38.774543 136209604935680 train.py:161] Sampling...\n","I0411 03:26:24.915062 136209604935680 train.py:138] Starting evaluation\n","I0411 03:26:47.738844 136209604935680 train.py:149] step: 16100, eval_loss: 3.62211e-02\n","I0411 03:28:08.272403 136209604935680 train.py:138] Starting evaluation\n","I0411 03:28:30.322870 136209604935680 train.py:149] step: 16200, eval_loss: 3.10157e-02\n","I0411 03:29:50.536071 136209604935680 train.py:138] Starting evaluation\n","I0411 03:30:12.683277 136209604935680 train.py:149] step: 16300, eval_loss: 3.18134e-02\n","I0411 03:31:33.673150 136209604935680 train.py:138] Starting evaluation\n","I0411 03:31:55.691599 136209604935680 train.py:149] step: 16400, eval_loss: 3.10507e-02\n","I0411 03:33:16.008450 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 03:33:20.045053 136209604935680 train.py:138] Starting evaluation\n","I0411 03:33:42.700630 136209604935680 train.py:149] step: 16500, eval_loss: 3.21286e-02\n","I0411 03:35:03.239693 136209604935680 train.py:138] Starting evaluation\n","I0411 03:35:25.311580 136209604935680 train.py:149] step: 16600, eval_loss: 3.50356e-02\n","I0411 03:36:45.761922 136209604935680 train.py:138] Starting evaluation\n","I0411 03:37:07.811390 136209604935680 train.py:149] step: 16700, eval_loss: 3.33888e-02\n","I0411 03:38:28.478689 136209604935680 train.py:138] Starting evaluation\n","I0411 03:38:49.884974 136209604935680 train.py:149] step: 16800, eval_loss: 4.15923e-02\n","I0411 03:40:10.456498 136209604935680 train.py:138] Starting evaluation\n","I0411 03:40:33.289116 136209604935680 train.py:149] step: 16900, eval_loss: 3.13032e-02\n","I0411 03:41:53.704762 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 03:42:00.521969 136209604935680 train.py:138] Starting evaluation\n","I0411 03:42:22.946738 136209604935680 train.py:149] step: 17000, eval_loss: 3.64177e-02\n","I0411 03:42:22.947389 136209604935680 train.py:161] Sampling...\n","I0411 03:45:09.485313 136209604935680 train.py:138] Starting evaluation\n","I0411 03:45:31.649733 136209604935680 train.py:149] step: 17100, eval_loss: 3.31340e-02\n","I0411 03:46:51.812552 136209604935680 train.py:138] Starting evaluation\n","I0411 03:47:13.783520 136209604935680 train.py:149] step: 17200, eval_loss: 4.10987e-02\n","I0411 03:48:34.254668 136209604935680 train.py:138] Starting evaluation\n","I0411 03:48:56.746592 136209604935680 train.py:149] step: 17300, eval_loss: 3.57659e-02\n","I0411 03:50:17.408133 136209604935680 train.py:138] Starting evaluation\n","I0411 03:50:39.560887 136209604935680 train.py:149] step: 17400, eval_loss: 3.29955e-02\n","I0411 03:51:59.878464 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 03:52:11.119260 136209604935680 train.py:138] Starting evaluation\n","I0411 03:52:33.402966 136209604935680 train.py:149] step: 17500, eval_loss: 3.30736e-02\n","I0411 03:53:54.007799 136209604935680 train.py:138] Starting evaluation\n","I0411 03:54:15.451391 136209604935680 train.py:149] step: 17600, eval_loss: 3.36168e-02\n","I0411 03:55:35.840645 136209604935680 train.py:138] Starting evaluation\n","I0411 03:55:58.647263 136209604935680 train.py:149] step: 17700, eval_loss: 3.25965e-02\n","I0411 03:57:19.060591 136209604935680 train.py:138] Starting evaluation\n","I0411 03:57:41.540702 136209604935680 train.py:149] step: 17800, eval_loss: 3.05531e-02\n","I0411 03:59:02.006125 136209604935680 train.py:138] Starting evaluation\n","I0411 03:59:24.220694 136209604935680 train.py:149] step: 17900, eval_loss: 3.17512e-02\n","I0411 04:00:44.543026 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:00:48.786991 136209604935680 train.py:138] Starting evaluation\n","I0411 04:01:10.886454 136209604935680 train.py:149] step: 18000, eval_loss: 3.77981e-02\n","I0411 04:01:10.887130 136209604935680 train.py:161] Sampling...\n","I0411 04:03:56.657638 136209604935680 train.py:138] Starting evaluation\n","I0411 04:04:18.766951 136209604935680 train.py:149] step: 18100, eval_loss: 3.31659e-02\n","I0411 04:05:39.089541 136209604935680 train.py:138] Starting evaluation\n","I0411 04:06:01.301397 136209604935680 train.py:149] step: 18200, eval_loss: 3.63405e-02\n","I0411 04:07:21.739239 136209604935680 train.py:138] Starting evaluation\n","I0411 04:07:44.300604 136209604935680 train.py:149] step: 18300, eval_loss: 3.13563e-02\n","I0411 04:09:04.738658 136209604935680 train.py:138] Starting evaluation\n","I0411 04:09:26.096333 136209604935680 train.py:149] step: 18400, eval_loss: 3.09441e-02\n","I0411 04:10:46.394024 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:10:50.415324 136209604935680 train.py:138] Starting evaluation\n","I0411 04:11:13.394290 136209604935680 train.py:149] step: 18500, eval_loss: 3.16725e-02\n","I0411 04:12:33.936370 136209604935680 train.py:138] Starting evaluation\n","I0411 04:12:56.339553 136209604935680 train.py:149] step: 18600, eval_loss: 3.36873e-02\n","I0411 04:14:17.317664 136209604935680 train.py:138] Starting evaluation\n","I0411 04:14:39.490501 136209604935680 train.py:149] step: 18700, eval_loss: 3.13279e-02\n","I0411 04:15:59.886919 136209604935680 train.py:138] Starting evaluation\n","I0411 04:16:21.934570 136209604935680 train.py:149] step: 18800, eval_loss: 3.05258e-02\n","I0411 04:17:42.114398 136209604935680 train.py:138] Starting evaluation\n","I0411 04:18:04.668500 136209604935680 train.py:149] step: 18900, eval_loss: 3.21382e-02\n","I0411 04:19:25.135899 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:19:33.346298 136209604935680 train.py:138] Starting evaluation\n","I0411 04:19:55.768534 136209604935680 train.py:149] step: 19000, eval_loss: 3.28441e-02\n","I0411 04:19:55.768802 136209604935680 train.py:161] Sampling...\n","I0411 04:22:42.649467 136209604935680 train.py:138] Starting evaluation\n","I0411 04:23:04.750200 136209604935680 train.py:149] step: 19100, eval_loss: 3.70677e-02\n","I0411 04:24:25.381690 136209604935680 train.py:138] Starting evaluation\n","I0411 04:24:46.720324 136209604935680 train.py:149] step: 19200, eval_loss: 3.76675e-02\n","I0411 04:26:07.380058 136209604935680 train.py:138] Starting evaluation\n","I0411 04:26:30.132748 136209604935680 train.py:149] step: 19300, eval_loss: 3.49120e-02\n","I0411 04:27:50.618823 136209604935680 train.py:138] Starting evaluation\n","I0411 04:28:12.640517 136209604935680 train.py:149] step: 19400, eval_loss: 3.40468e-02\n","I0411 04:29:33.367171 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:29:38.783097 136209604935680 train.py:138] Starting evaluation\n","I0411 04:30:01.106550 136209604935680 train.py:149] step: 19500, eval_loss: 3.06376e-02\n","I0411 04:31:21.642352 136209604935680 train.py:138] Starting evaluation\n","I0411 04:31:44.154179 136209604935680 train.py:149] step: 19600, eval_loss: 3.51998e-02\n","I0411 04:33:04.472658 136209604935680 train.py:138] Starting evaluation\n","I0411 04:33:26.495258 136209604935680 train.py:149] step: 19700, eval_loss: 3.98764e-02\n","I0411 04:34:47.048702 136209604935680 train.py:138] Starting evaluation\n","I0411 04:35:09.205067 136209604935680 train.py:149] step: 19800, eval_loss: 3.45056e-02\n","I0411 04:36:29.986447 136209604935680 train.py:138] Starting evaluation\n","I0411 04:36:52.467998 136209604935680 train.py:149] step: 19900, eval_loss: 3.49352e-02\n","I0411 04:38:12.905566 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:38:20.352615 136209604935680 train.py:138] Starting evaluation\n","I0411 04:38:41.887420 136209604935680 train.py:149] step: 20000, eval_loss: 2.42535e-02\n","I0411 04:38:41.887709 136209604935680 train.py:161] Sampling...\n","I0411 04:41:28.055514 136209604935680 train.py:138] Starting evaluation\n","I0411 04:41:50.953467 136209604935680 train.py:149] step: 20100, eval_loss: 3.27557e-02\n","I0411 04:43:11.725749 136209604935680 train.py:138] Starting evaluation\n","I0411 04:43:33.812496 136209604935680 train.py:149] step: 20200, eval_loss: 3.16949e-02\n","I0411 04:44:54.434660 136209604935680 train.py:138] Starting evaluation\n","I0411 04:45:16.583860 136209604935680 train.py:149] step: 20300, eval_loss: 2.67223e-02\n","I0411 04:46:37.263041 136209604935680 train.py:138] Starting evaluation\n","I0411 04:46:59.405974 136209604935680 train.py:149] step: 20400, eval_loss: 2.90096e-02\n","I0411 04:48:20.255058 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:48:28.723609 136209604935680 train.py:138] Starting evaluation\n","I0411 04:48:51.287886 136209604935680 train.py:149] step: 20500, eval_loss: 3.06785e-02\n","I0411 04:50:12.441130 136209604935680 train.py:138] Starting evaluation\n","I0411 04:50:34.673034 136209604935680 train.py:149] step: 20600, eval_loss: 3.45835e-02\n","I0411 04:51:55.146873 136209604935680 train.py:138] Starting evaluation\n","I0411 04:52:17.108894 136209604935680 train.py:149] step: 20700, eval_loss: 2.95653e-02\n","I0411 04:53:37.672566 136209604935680 train.py:138] Starting evaluation\n","I0411 04:53:59.060103 136209604935680 train.py:149] step: 20800, eval_loss: 4.45577e-02\n","I0411 04:55:19.226825 136209604935680 train.py:138] Starting evaluation\n","I0411 04:55:42.046200 136209604935680 train.py:149] step: 20900, eval_loss: 3.14352e-02\n","I0411 04:57:02.494868 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 04:57:12.304267 136209604935680 train.py:138] Starting evaluation\n","I0411 04:57:34.761610 136209604935680 train.py:149] step: 21000, eval_loss: 3.10912e-02\n","I0411 04:57:34.762361 136209604935680 train.py:161] Sampling...\n","I0411 05:00:21.120110 136209604935680 train.py:138] Starting evaluation\n","I0411 05:00:43.223128 136209604935680 train.py:149] step: 21100, eval_loss: 3.51219e-02\n","I0411 05:02:03.653198 136209604935680 train.py:138] Starting evaluation\n","I0411 05:02:25.758790 136209604935680 train.py:149] step: 21200, eval_loss: 3.20985e-02\n","I0411 05:03:46.130441 136209604935680 train.py:138] Starting evaluation\n","I0411 05:04:08.149464 136209604935680 train.py:149] step: 21300, eval_loss: 3.19528e-02\n","I0411 05:05:28.968034 136209604935680 train.py:138] Starting evaluation\n","I0411 05:05:51.219063 136209604935680 train.py:149] step: 21400, eval_loss: 3.32767e-02\n","I0411 05:07:11.502394 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 05:07:23.425048 136209604935680 train.py:138] Starting evaluation\n","I0411 05:07:46.306200 136209604935680 train.py:149] step: 21500, eval_loss: 3.06192e-02\n","I0411 05:09:06.872467 136209604935680 train.py:138] Starting evaluation\n","I0411 05:09:28.330282 136209604935680 train.py:149] step: 21600, eval_loss: 3.71564e-02\n","I0411 05:10:48.780749 136209604935680 train.py:138] Starting evaluation\n","I0411 05:11:11.586378 136209604935680 train.py:149] step: 21700, eval_loss: 3.16317e-02\n","I0411 05:12:32.577191 136209604935680 train.py:138] Starting evaluation\n","I0411 05:12:55.071270 136209604935680 train.py:149] step: 21800, eval_loss: 2.93096e-02\n","I0411 05:14:15.527903 136209604935680 train.py:138] Starting evaluation\n","I0411 05:14:37.724777 136209604935680 train.py:149] step: 21900, eval_loss: 3.72001e-02\n","I0411 05:15:57.824215 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 05:16:07.923271 136209604935680 train.py:138] Starting evaluation\n","I0411 05:16:30.557223 136209604935680 train.py:149] step: 22000, eval_loss: 3.48220e-02\n","I0411 05:16:30.557813 136209604935680 train.py:161] Sampling...\n","I0411 05:19:17.010641 136209604935680 train.py:138] Starting evaluation\n","I0411 05:19:38.920563 136209604935680 train.py:149] step: 22100, eval_loss: 3.18080e-02\n","I0411 05:20:59.947046 136209604935680 train.py:138] Starting evaluation\n","I0411 05:21:22.068535 136209604935680 train.py:149] step: 22200, eval_loss: 3.10668e-02\n","I0411 05:22:42.577139 136209604935680 train.py:138] Starting evaluation\n","I0411 05:23:04.704263 136209604935680 train.py:149] step: 22300, eval_loss: 3.30951e-02\n","I0411 05:24:25.048202 136209604935680 train.py:138] Starting evaluation\n","I0411 05:24:46.393273 136209604935680 train.py:149] step: 22400, eval_loss: 4.22598e-02\n","I0411 05:26:07.105660 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 05:26:11.145194 136209604935680 train.py:138] Starting evaluation\n","I0411 05:26:35.025755 136209604935680 train.py:149] step: 22500, eval_loss: 3.74273e-02\n","I0411 05:27:55.959510 136209604935680 train.py:138] Starting evaluation\n","I0411 05:28:18.008776 136209604935680 train.py:149] step: 22600, eval_loss: 2.86367e-02\n","I0411 05:29:38.198739 136209604935680 train.py:138] Starting evaluation\n","I0411 05:30:00.384325 136209604935680 train.py:149] step: 22700, eval_loss: 3.46349e-02\n","I0411 05:31:21.093745 136209604935680 train.py:138] Starting evaluation\n","I0411 05:31:43.052955 136209604935680 train.py:149] step: 22800, eval_loss: 3.51632e-02\n","I0411 05:33:03.575099 136209604935680 train.py:138] Starting evaluation\n","I0411 05:33:25.772293 136209604935680 train.py:149] step: 22900, eval_loss: 3.08583e-02\n","I0411 05:34:46.460417 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 05:34:57.685739 136209604935680 train.py:138] Starting evaluation\n","I0411 05:35:19.986863 136209604935680 train.py:149] step: 23000, eval_loss: 3.60059e-02\n","I0411 05:35:19.987154 136209604935680 train.py:161] Sampling...\n","I0411 05:38:06.672535 136209604935680 train.py:138] Starting evaluation\n","I0411 05:38:28.781547 136209604935680 train.py:149] step: 23100, eval_loss: 3.65679e-02\n","I0411 05:39:49.271112 136209604935680 train.py:138] Starting evaluation\n","I0411 05:40:10.625109 136209604935680 train.py:149] step: 23200, eval_loss: 3.32240e-02\n","I0411 05:41:30.811061 136209604935680 train.py:138] Starting evaluation\n","I0411 05:41:53.616577 136209604935680 train.py:149] step: 23300, eval_loss: 3.42327e-02\n","I0411 05:43:14.245772 136209604935680 train.py:138] Starting evaluation\n","I0411 05:43:36.317260 136209604935680 train.py:149] step: 23400, eval_loss: 3.63534e-02\n","I0411 05:44:56.740856 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 05:45:04.175848 136209604935680 train.py:138] Starting evaluation\n","I0411 05:45:26.619389 136209604935680 train.py:149] step: 23500, eval_loss: 3.26257e-02\n","I0411 05:46:47.271253 136209604935680 train.py:138] Starting evaluation\n","I0411 05:47:09.303890 136209604935680 train.py:149] step: 23600, eval_loss: 3.28841e-02\n","I0411 05:48:30.010379 136209604935680 train.py:138] Starting evaluation\n","I0411 05:48:51.831172 136209604935680 train.py:149] step: 23700, eval_loss: 3.16802e-02\n","I0411 05:50:12.207270 136209604935680 train.py:138] Starting evaluation\n","I0411 05:50:34.249790 136209604935680 train.py:149] step: 23800, eval_loss: 2.84810e-02\n","I0411 05:51:54.620102 136209604935680 train.py:138] Starting evaluation\n","I0411 05:52:16.634292 136209604935680 train.py:149] step: 23900, eval_loss: 3.44414e-02\n","I0411 05:53:37.089559 136209604935680 train.py:133] Saving temporary checkpoint\n","I0411 05:53:47.758271 136209604935680 train.py:138] Starting evaluation\n","I0411 05:54:09.238848 136209604935680 train.py:149] step: 24000, eval_loss: 5.62019e-02\n","I0411 05:54:09.239205 136209604935680 train.py:161] Sampling...\n","I0411 05:56:55.789801 136209604935680 train.py:138] Starting evaluation\n","I0411 05:57:18.956489 136209604935680 train.py:149] step: 24100, eval_loss: 3.36666e-02\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/train.py\", line 177, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/train.py\", line 27, in main\n","    train(FLAGS.config, FLAGS.workdir,FLAGS.blur_type)\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/train.py\", line 127, in train\n","    loss, losses_batch, fwd_steps_batch = train_step_fn(state, batch)\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/scripts/losses.py\", line 111, in step_fn\n","    scaler.scale(loss).backward()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["# train model with cifar10 dataset\n","# bluring method : fftblur\n","# end iter : 0\n","!python train.py --config configs/cifar10/default_cifar10_configs.py --blur_type fftblur --workdir ./runs/cifar/fftblur_scale800"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"um1WbslRSbLk","executionInfo":{"status":"ok","timestamp":1713213481516,"user_tz":-210,"elapsed":7584832,"user":{"displayName":"Mehdi “Dehghani”","userId":"11956428046354443444"}},"outputId":"4c66a6f5-5b52-42c3-9b95-eb2555a18cba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-15 17:19:01.998362: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-15 17:19:01.998423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-15 17:19:02.000291: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-15 17:19:03.187057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","initial_step: 14001\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Files already downloaded and verified\n","Files already downloaded and verified\n","I0415 17:19:47.969755 137176723496960 train.py:114] Starting training loop at step 14001.\n","I0415 17:19:47.970309 137176723496960 train.py:115] Running on cuda:0\n","I0415 17:21:09.608181 137176723496960 train.py:138] Starting evaluation\n","I0415 17:21:33.371410 137176723496960 train.py:149] step: 14100, eval_loss: 3.94386e-02\n","I0415 17:22:56.462938 137176723496960 train.py:138] Starting evaluation\n","I0415 17:23:19.400465 137176723496960 train.py:149] step: 14200, eval_loss: 3.42821e-02\n","I0415 17:24:42.207939 137176723496960 train.py:138] Starting evaluation\n","I0415 17:25:05.360357 137176723496960 train.py:149] step: 14300, eval_loss: 4.14434e-02\n","I0415 17:26:28.707154 137176723496960 train.py:138] Starting evaluation\n","I0415 17:26:51.984595 137176723496960 train.py:149] step: 14400, eval_loss: 3.28671e-02\n","I0415 17:28:15.138623 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 17:28:22.298273 137176723496960 train.py:138] Starting evaluation\n","I0415 17:28:45.264188 137176723496960 train.py:149] step: 14500, eval_loss: 3.47958e-02\n","I0415 17:30:08.723796 137176723496960 train.py:138] Starting evaluation\n","I0415 17:30:32.018565 137176723496960 train.py:149] step: 14600, eval_loss: 3.77428e-02\n","I0415 17:31:54.915230 137176723496960 train.py:138] Starting evaluation\n","I0415 17:32:17.814455 137176723496960 train.py:149] step: 14700, eval_loss: 3.89319e-02\n","I0415 17:33:41.143946 137176723496960 train.py:138] Starting evaluation\n","I0415 17:34:03.557969 137176723496960 train.py:149] step: 14800, eval_loss: 5.29436e-02\n","I0415 17:35:26.516493 137176723496960 train.py:138] Starting evaluation\n","I0415 17:35:50.138991 137176723496960 train.py:149] step: 14900, eval_loss: 3.62138e-02\n","I0415 17:37:13.174529 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 17:37:21.760771 137176723496960 train.py:138] Starting evaluation\n","I0415 17:37:44.928665 137176723496960 train.py:149] step: 15000, eval_loss: 3.41900e-02\n","I0415 17:37:44.929209 137176723496960 train.py:161] Sampling...\n","I0415 17:40:38.408172 137176723496960 train.py:138] Starting evaluation\n","I0415 17:41:01.611320 137176723496960 train.py:149] step: 15100, eval_loss: 4.07524e-02\n","I0415 17:42:25.149468 137176723496960 train.py:138] Starting evaluation\n","I0415 17:42:48.081731 137176723496960 train.py:149] step: 15200, eval_loss: 3.54713e-02\n","I0415 17:44:11.627409 137176723496960 train.py:138] Starting evaluation\n","I0415 17:44:34.654875 137176723496960 train.py:149] step: 15300, eval_loss: 3.78092e-02\n","I0415 17:45:58.118048 137176723496960 train.py:138] Starting evaluation\n","I0415 17:46:21.239839 137176723496960 train.py:149] step: 15400, eval_loss: 3.93253e-02\n","I0415 17:47:44.380857 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 17:47:54.841814 137176723496960 train.py:138] Starting evaluation\n","I0415 17:48:18.175713 137176723496960 train.py:149] step: 15500, eval_loss: 3.64490e-02\n","I0415 17:49:41.750979 137176723496960 train.py:138] Starting evaluation\n","I0415 17:50:04.322843 137176723496960 train.py:149] step: 15600, eval_loss: 5.12802e-02\n","I0415 17:51:27.133571 137176723496960 train.py:138] Starting evaluation\n","I0415 17:51:50.908467 137176723496960 train.py:149] step: 15700, eval_loss: 3.27406e-02\n","I0415 17:53:14.093882 137176723496960 train.py:138] Starting evaluation\n","I0415 17:53:36.927788 137176723496960 train.py:149] step: 15800, eval_loss: 3.37346e-02\n","I0415 17:54:59.937940 137176723496960 train.py:138] Starting evaluation\n","I0415 17:55:23.134203 137176723496960 train.py:149] step: 15900, eval_loss: 4.11146e-02\n","I0415 17:56:46.366306 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 17:56:51.733761 137176723496960 train.py:138] Starting evaluation\n","I0415 17:57:15.055660 137176723496960 train.py:149] step: 16000, eval_loss: 3.82662e-02\n","I0415 17:57:15.056246 137176723496960 train.py:161] Sampling...\n","I0415 18:00:08.461942 137176723496960 train.py:138] Starting evaluation\n","I0415 18:00:31.334284 137176723496960 train.py:149] step: 16100, eval_loss: 3.49150e-02\n","I0415 18:01:54.373416 137176723496960 train.py:138] Starting evaluation\n","I0415 18:02:17.504961 137176723496960 train.py:149] step: 16200, eval_loss: 4.27793e-02\n","I0415 18:03:40.624449 137176723496960 train.py:138] Starting evaluation\n","I0415 18:04:03.969908 137176723496960 train.py:149] step: 16300, eval_loss: 4.24943e-02\n","I0415 18:05:27.142729 137176723496960 train.py:138] Starting evaluation\n","I0415 18:05:49.515168 137176723496960 train.py:149] step: 16400, eval_loss: 4.84405e-02\n","I0415 18:07:12.552462 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 18:07:16.412725 137176723496960 train.py:138] Starting evaluation\n","I0415 18:07:42.083808 137176723496960 train.py:149] step: 16500, eval_loss: 3.78439e-02\n","I0415 18:09:05.137925 137176723496960 train.py:138] Starting evaluation\n","I0415 18:09:28.241188 137176723496960 train.py:149] step: 16600, eval_loss: 3.48393e-02\n","I0415 18:10:51.276521 137176723496960 train.py:138] Starting evaluation\n","I0415 18:11:14.440292 137176723496960 train.py:149] step: 16700, eval_loss: 3.28691e-02\n","I0415 18:12:37.508751 137176723496960 train.py:138] Starting evaluation\n","I0415 18:13:00.489264 137176723496960 train.py:149] step: 16800, eval_loss: 3.83535e-02\n","I0415 18:14:23.619318 137176723496960 train.py:138] Starting evaluation\n","I0415 18:14:46.567713 137176723496960 train.py:149] step: 16900, eval_loss: 3.41235e-02\n","I0415 18:16:09.550298 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 18:16:13.158636 137176723496960 train.py:138] Starting evaluation\n","I0415 18:16:36.470792 137176723496960 train.py:149] step: 17000, eval_loss: 3.55556e-02\n","I0415 18:16:36.470999 137176723496960 train.py:161] Sampling...\n","I0415 18:19:29.956773 137176723496960 train.py:138] Starting evaluation\n","I0415 18:19:52.870041 137176723496960 train.py:149] step: 17100, eval_loss: 3.45571e-02\n","I0415 18:21:16.347892 137176723496960 train.py:138] Starting evaluation\n","I0415 18:21:38.788156 137176723496960 train.py:149] step: 17200, eval_loss: 2.77711e-02\n","I0415 18:23:01.931927 137176723496960 train.py:138] Starting evaluation\n","I0415 18:23:26.133798 137176723496960 train.py:149] step: 17300, eval_loss: 3.59996e-02\n","I0415 18:24:49.249660 137176723496960 train.py:138] Starting evaluation\n","I0415 18:25:12.509437 137176723496960 train.py:149] step: 17400, eval_loss: 3.75194e-02\n","I0415 18:26:35.674834 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 18:26:50.910724 137176723496960 train.py:138] Starting evaluation\n","I0415 18:27:14.251116 137176723496960 train.py:149] step: 17500, eval_loss: 3.66324e-02\n","I0415 18:28:37.547915 137176723496960 train.py:138] Starting evaluation\n","I0415 18:29:00.621840 137176723496960 train.py:149] step: 17600, eval_loss: 3.67086e-02\n","I0415 18:30:23.696999 137176723496960 train.py:138] Starting evaluation\n","I0415 18:30:46.539520 137176723496960 train.py:149] step: 17700, eval_loss: 3.69899e-02\n","I0415 18:32:09.821996 137176723496960 train.py:138] Starting evaluation\n","I0415 18:32:32.901898 137176723496960 train.py:149] step: 17800, eval_loss: 3.68269e-02\n","I0415 18:33:55.964386 137176723496960 train.py:138] Starting evaluation\n","I0415 18:34:18.668798 137176723496960 train.py:149] step: 17900, eval_loss: 3.62292e-02\n","I0415 18:35:42.076836 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 18:35:45.801384 137176723496960 train.py:138] Starting evaluation\n","I0415 18:36:08.254962 137176723496960 train.py:149] step: 18000, eval_loss: 4.99415e-02\n","I0415 18:36:08.255169 137176723496960 train.py:161] Sampling...\n","I0415 18:39:01.608260 137176723496960 train.py:138] Starting evaluation\n","I0415 18:39:25.462516 137176723496960 train.py:149] step: 18100, eval_loss: 3.88637e-02\n","I0415 18:40:48.434886 137176723496960 train.py:138] Starting evaluation\n","I0415 18:41:11.728966 137176723496960 train.py:149] step: 18200, eval_loss: 3.67462e-02\n","I0415 18:42:34.931025 137176723496960 train.py:138] Starting evaluation\n","I0415 18:42:58.152772 137176723496960 train.py:149] step: 18300, eval_loss: 3.35434e-02\n","I0415 18:44:21.592005 137176723496960 train.py:138] Starting evaluation\n","I0415 18:44:44.463281 137176723496960 train.py:149] step: 18400, eval_loss: 3.25838e-02\n","I0415 18:46:07.836569 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 18:46:20.182948 137176723496960 train.py:138] Starting evaluation\n","I0415 18:46:43.153928 137176723496960 train.py:149] step: 18500, eval_loss: 3.37096e-02\n","I0415 18:48:06.753429 137176723496960 train.py:138] Starting evaluation\n","I0415 18:48:30.126078 137176723496960 train.py:149] step: 18600, eval_loss: 3.44601e-02\n","I0415 18:49:53.259453 137176723496960 train.py:138] Starting evaluation\n","I0415 18:50:16.431237 137176723496960 train.py:149] step: 18700, eval_loss: 3.67636e-02\n","I0415 18:51:39.515673 137176723496960 train.py:138] Starting evaluation\n","I0415 18:52:01.811531 137176723496960 train.py:149] step: 18800, eval_loss: 2.62425e-02\n","I0415 18:53:24.857030 137176723496960 train.py:138] Starting evaluation\n","I0415 18:53:48.650027 137176723496960 train.py:149] step: 18900, eval_loss: 3.66191e-02\n","I0415 18:55:11.788892 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 18:55:15.491573 137176723496960 train.py:138] Starting evaluation\n","I0415 18:55:38.674266 137176723496960 train.py:149] step: 19000, eval_loss: 3.46744e-02\n","I0415 18:55:38.674847 137176723496960 train.py:161] Sampling...\n","I0415 18:58:32.037030 137176723496960 train.py:138] Starting evaluation\n","I0415 18:58:55.220003 137176723496960 train.py:149] step: 19100, eval_loss: 3.36491e-02\n","I0415 19:00:18.598650 137176723496960 train.py:138] Starting evaluation\n","I0415 19:00:41.702802 137176723496960 train.py:149] step: 19200, eval_loss: 3.98740e-02\n","I0415 19:02:04.833157 137176723496960 train.py:138] Starting evaluation\n","I0415 19:02:27.690178 137176723496960 train.py:149] step: 19300, eval_loss: 3.39437e-02\n","I0415 19:03:50.771501 137176723496960 train.py:138] Starting evaluation\n","I0415 19:04:13.909555 137176723496960 train.py:149] step: 19400, eval_loss: 4.16795e-02\n","I0415 19:05:37.260183 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 19:05:41.266767 137176723496960 train.py:138] Starting evaluation\n","I0415 19:06:04.831918 137176723496960 train.py:149] step: 19500, eval_loss: 3.66540e-02\n","I0415 19:07:28.077328 137176723496960 train.py:138] Starting evaluation\n","I0415 19:07:50.516893 137176723496960 train.py:149] step: 19600, eval_loss: 3.32769e-02\n","I0415 19:09:13.845913 137176723496960 train.py:138] Starting evaluation\n","I0415 19:09:37.612084 137176723496960 train.py:149] step: 19700, eval_loss: 4.26084e-02\n","I0415 19:11:00.958265 137176723496960 train.py:138] Starting evaluation\n","I0415 19:11:23.984440 137176723496960 train.py:149] step: 19800, eval_loss: 3.16775e-02\n","I0415 19:12:47.253803 137176723496960 train.py:138] Starting evaluation\n","I0415 19:13:10.372384 137176723496960 train.py:149] step: 19900, eval_loss: 3.48149e-02\n","I0415 19:14:33.614185 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 19:14:37.990195 137176723496960 train.py:138] Starting evaluation\n","I0415 19:15:00.930078 137176723496960 train.py:149] step: 20000, eval_loss: 3.39019e-02\n","I0415 19:15:00.930567 137176723496960 train.py:161] Sampling...\n","I0415 19:17:54.771036 137176723496960 train.py:138] Starting evaluation\n","I0415 19:18:17.708893 137176723496960 train.py:149] step: 20100, eval_loss: 3.30687e-02\n","I0415 19:19:40.660415 137176723496960 train.py:138] Starting evaluation\n","I0415 19:20:03.870504 137176723496960 train.py:149] step: 20200, eval_loss: 3.68161e-02\n","I0415 19:21:27.344076 137176723496960 train.py:138] Starting evaluation\n","I0415 19:21:50.245023 137176723496960 train.py:149] step: 20300, eval_loss: 3.50689e-02\n","I0415 19:23:13.786679 137176723496960 train.py:138] Starting evaluation\n","I0415 19:23:36.135990 137176723496960 train.py:149] step: 20400, eval_loss: 4.58218e-02\n","I0415 19:24:59.244971 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 19:25:06.153411 137176723496960 train.py:138] Starting evaluation\n","I0415 19:25:29.867771 137176723496960 train.py:149] step: 20500, eval_loss: 3.25628e-02\n","I0415 19:26:53.217935 137176723496960 train.py:138] Starting evaluation\n","I0415 19:27:16.256885 137176723496960 train.py:149] step: 20600, eval_loss: 3.60266e-02\n","I0415 19:28:39.407549 137176723496960 train.py:138] Starting evaluation\n","I0415 19:29:02.634940 137176723496960 train.py:149] step: 20700, eval_loss: 3.80459e-02\n","I0415 19:30:25.571085 137176723496960 train.py:138] Starting evaluation\n","I0415 19:30:48.462382 137176723496960 train.py:149] step: 20800, eval_loss: 3.57931e-02\n","I0415 19:32:11.703547 137176723496960 train.py:138] Starting evaluation\n","I0415 19:32:34.692727 137176723496960 train.py:149] step: 20900, eval_loss: 3.43802e-02\n","I0415 19:33:57.846022 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 19:34:03.033113 137176723496960 train.py:138] Starting evaluation\n","I0415 19:34:26.349831 137176723496960 train.py:149] step: 21000, eval_loss: 3.96541e-02\n","I0415 19:34:26.350122 137176723496960 train.py:161] Sampling...\n","I0415 19:37:19.895040 137176723496960 train.py:138] Starting evaluation\n","I0415 19:37:42.829087 137176723496960 train.py:149] step: 21100, eval_loss: 3.22106e-02\n","I0415 19:39:05.922782 137176723496960 train.py:138] Starting evaluation\n","I0415 19:39:28.273171 137176723496960 train.py:149] step: 21200, eval_loss: 3.43309e-02\n","I0415 19:40:51.303144 137176723496960 train.py:138] Starting evaluation\n","I0415 19:41:15.086211 137176723496960 train.py:149] step: 21300, eval_loss: 3.43791e-02\n","I0415 19:42:38.215323 137176723496960 train.py:138] Starting evaluation\n","I0415 19:43:01.191899 137176723496960 train.py:149] step: 21400, eval_loss: 3.71039e-02\n","I0415 19:44:24.253760 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 19:44:35.146060 137176723496960 train.py:138] Starting evaluation\n","I0415 19:44:58.430466 137176723496960 train.py:149] step: 21500, eval_loss: 3.35102e-02\n","I0415 19:46:22.043773 137176723496960 train.py:138] Starting evaluation\n","I0415 19:46:45.317877 137176723496960 train.py:149] step: 21600, eval_loss: 3.62988e-02\n","I0415 19:48:08.459425 137176723496960 train.py:138] Starting evaluation\n","I0415 19:48:31.555709 137176723496960 train.py:149] step: 21700, eval_loss: 3.46399e-02\n","I0415 19:49:54.583042 137176723496960 train.py:138] Starting evaluation\n","I0415 19:50:17.744055 137176723496960 train.py:149] step: 21800, eval_loss: 3.55729e-02\n","I0415 19:51:41.237374 137176723496960 train.py:138] Starting evaluation\n","I0415 19:52:04.198230 137176723496960 train.py:149] step: 21900, eval_loss: 4.06738e-02\n","I0415 19:53:27.357662 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 19:53:40.136943 137176723496960 train.py:138] Starting evaluation\n","I0415 19:54:02.491674 137176723496960 train.py:149] step: 22000, eval_loss: 2.16935e-02\n","I0415 19:54:02.491876 137176723496960 train.py:161] Sampling...\n","I0415 19:56:56.465613 137176723496960 train.py:138] Starting evaluation\n","I0415 19:57:20.273394 137176723496960 train.py:149] step: 22100, eval_loss: 3.49188e-02\n","I0415 19:58:43.405059 137176723496960 train.py:138] Starting evaluation\n","I0415 19:59:06.308810 137176723496960 train.py:149] step: 22200, eval_loss: 3.63103e-02\n","I0415 20:00:29.675088 137176723496960 train.py:138] Starting evaluation\n","I0415 20:00:52.953436 137176723496960 train.py:149] step: 22300, eval_loss: 3.68927e-02\n","I0415 20:02:15.960667 137176723496960 train.py:138] Starting evaluation\n","I0415 20:02:38.865350 137176723496960 train.py:149] step: 22400, eval_loss: 3.31615e-02\n","I0415 20:04:01.918139 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 20:04:10.357768 137176723496960 train.py:138] Starting evaluation\n","I0415 20:04:33.441410 137176723496960 train.py:149] step: 22500, eval_loss: 4.32745e-02\n","I0415 20:05:56.645016 137176723496960 train.py:138] Starting evaluation\n","I0415 20:06:20.008385 137176723496960 train.py:149] step: 22600, eval_loss: 3.36450e-02\n","I0415 20:07:43.182539 137176723496960 train.py:138] Starting evaluation\n","I0415 20:08:06.486170 137176723496960 train.py:149] step: 22700, eval_loss: 3.87115e-02\n","I0415 20:09:29.566677 137176723496960 train.py:138] Starting evaluation\n","I0415 20:09:51.919859 137176723496960 train.py:149] step: 22800, eval_loss: 5.33039e-02\n","I0415 20:11:15.318806 137176723496960 train.py:138] Starting evaluation\n","I0415 20:11:38.965337 137176723496960 train.py:149] step: 22900, eval_loss: 3.42060e-02\n","I0415 20:13:02.147346 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 20:13:05.792630 137176723496960 train.py:138] Starting evaluation\n","I0415 20:13:29.210859 137176723496960 train.py:149] step: 23000, eval_loss: 3.55214e-02\n","I0415 20:13:29.211685 137176723496960 train.py:161] Sampling...\n","I0415 20:16:22.816467 137176723496960 train.py:138] Starting evaluation\n","I0415 20:16:45.939350 137176723496960 train.py:149] step: 23100, eval_loss: 3.67733e-02\n","I0415 20:18:08.932588 137176723496960 train.py:138] Starting evaluation\n","I0415 20:18:31.830229 137176723496960 train.py:149] step: 23200, eval_loss: 3.50985e-02\n","I0415 20:19:55.003023 137176723496960 train.py:138] Starting evaluation\n","I0415 20:20:17.958523 137176723496960 train.py:149] step: 23300, eval_loss: 3.87549e-02\n","I0415 20:21:41.557205 137176723496960 train.py:138] Starting evaluation\n","I0415 20:22:04.769806 137176723496960 train.py:149] step: 23400, eval_loss: 3.87404e-02\n","I0415 20:23:27.997902 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 20:23:35.319197 137176723496960 train.py:138] Starting evaluation\n","I0415 20:23:58.431717 137176723496960 train.py:149] step: 23500, eval_loss: 3.35973e-02\n","I0415 20:25:21.802820 137176723496960 train.py:138] Starting evaluation\n","I0415 20:25:44.272591 137176723496960 train.py:149] step: 23600, eval_loss: 3.61877e-02\n","I0415 20:27:07.361075 137176723496960 train.py:138] Starting evaluation\n","I0415 20:27:31.103022 137176723496960 train.py:149] step: 23700, eval_loss: 3.65224e-02\n","I0415 20:28:54.220436 137176723496960 train.py:138] Starting evaluation\n","I0415 20:29:17.616625 137176723496960 train.py:149] step: 23800, eval_loss: 3.42956e-02\n","I0415 20:30:40.853544 137176723496960 train.py:138] Starting evaluation\n","I0415 20:31:04.091098 137176723496960 train.py:149] step: 23900, eval_loss: 3.54144e-02\n","I0415 20:32:27.318937 137176723496960 train.py:133] Saving temporary checkpoint\n","I0415 20:32:31.230372 137176723496960 train.py:138] Starting evaluation\n","I0415 20:32:54.227719 137176723496960 train.py:149] step: 24000, eval_loss: 3.47981e-02\n","I0415 20:32:54.228314 137176723496960 train.py:161] Sampling...\n","I0415 20:35:47.407159 137176723496960 train.py:138] Starting evaluation\n","I0415 20:36:10.348713 137176723496960 train.py:149] step: 24100, eval_loss: 3.32344e-02\n","Traceback (most recent call last):\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/train.py\", line 178, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/train.py\", line 27, in main\n","    train(FLAGS.config, FLAGS.workdir,FLAGS.blur_type)\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/train.py\", line 127, in train\n","    loss, losses_batch, fwd_steps_batch = train_step_fn(state, batch)\n","  File \"/content/drive/.shortcut-targets-by-id/10DJu4TqH_H_4VmdC2S9-vHrJHIb6GZaj/diffusion/generative-inverse-heat-dissipation/scripts/losses.py\", line 111, in step_fn\n","    scaler.scale(loss).backward()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\", line 522, in backward\n","    torch.autograd.backward(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\", line 266, in backward\n","    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","source":["# train model with cifar10 dataset\n","# bluring method : fftblur_edgefilter\n","# end iter : 0\n","!python train.py --config configs/cifar10/default_cifar10_configs.py --blur_type fftblur --workdir ./runs/cifar/fftblur_laplacianfilter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o3yMrOPQ9YQb","executionInfo":{"status":"ok","timestamp":1713276735847,"user_tz":-210,"elapsed":137413,"user":{"displayName":"mehdi dehghani","userId":"16329055276283908551"}},"outputId":"0955fac7-fcf2-4a27-ef69-ee5dfab5bc0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-04-16 13:40:40.333221: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-16 13:40:40.333284: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-16 13:40:40.334649: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-16 13:40:41.507428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","initial_step: 1001\n","Files already downloaded and verified\n","Files already downloaded and verified\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","Files already downloaded and verified\n","Files already downloaded and verified\n","I0416 13:40:53.227892 137620239122432 train.py:114] Starting training loop at step 1001.\n","I0416 13:40:53.228445 137620239122432 train.py:115] Running on cuda:0\n","I0416 13:42:02.370569 137620239122432 train.py:138] Starting evaluation\n","I0416 13:42:23.035449 137620239122432 train.py:149] step: 1100, eval_loss: nan\n","I0416 13:43:33.980254 137620239122432 train.py:138] Starting evaluation\n","I0416 13:43:55.387364 137620239122432 train.py:149] step: 1200, eval_loss: nan\n","I0416 13:45:07.554496 137620239122432 train.py:138] Starting evaluation\n","I0416 13:45:29.544378 137620239122432 train.py:149] step: 1300, eval_loss: nan\n","I0416 13:46:42.493360 137620239122432 train.py:138] Starting evaluation\n","I0416 13:47:04.551459 137620239122432 train.py:149] step: 1400, eval_loss: nan\n","I0416 13:48:17.376851 137620239122432 train.py:133] Saving temporary checkpoint\n","I0416 13:48:25.508137 137620239122432 train.py:138] Starting evaluation\n","I0416 13:48:47.997970 137620239122432 train.py:149] step: 1500, eval_loss: nan\n","I0416 13:50:00.691553 137620239122432 train.py:138] Starting evaluation\n","I0416 13:50:22.952476 137620239122432 train.py:149] step: 1600, eval_loss: nan\n","I0416 13:51:35.949100 137620239122432 train.py:138] Starting evaluation\n","I0416 13:51:57.886765 137620239122432 train.py:149] step: 1700, eval_loss: nan\n","I0416 13:53:11.353633 137620239122432 train.py:138] Starting evaluation\n","I0416 13:53:32.921472 137620239122432 train.py:149] step: 1800, eval_loss: nan\n","I0416 13:54:46.506347 137620239122432 train.py:138] Starting evaluation\n","I0416 13:55:09.697372 137620239122432 train.py:149] step: 1900, eval_loss: nan\n","I0416 13:56:23.615692 137620239122432 train.py:133] Saving temporary checkpoint\n","I0416 13:56:31.575491 137620239122432 train.py:138] Starting evaluation\n","I0416 13:56:54.460218 137620239122432 train.py:149] step: 2000, eval_loss: nan\n","I0416 13:56:54.460877 137620239122432 train.py:161] Sampling...\n","I0416 13:59:27.996500 137620239122432 train.py:138] Starting evaluation\n","I0416 13:59:50.631134 137620239122432 train.py:149] step: 2100, eval_loss: nan\n","I0416 14:01:04.720633 137620239122432 train.py:138] Starting evaluation\n","I0416 14:01:27.195994 137620239122432 train.py:149] step: 2200, eval_loss: nan\n","I0416 14:02:41.013837 137620239122432 train.py:138] Starting evaluation\n","I0416 14:03:03.503357 137620239122432 train.py:149] step: 2300, eval_loss: nan\n","I0416 14:04:17.224390 137620239122432 train.py:138] Starting evaluation\n","I0416 14:04:39.973870 137620239122432 train.py:149] step: 2400, eval_loss: nan\n","I0416 14:05:53.575483 137620239122432 train.py:133] Saving temporary checkpoint\n","I0416 14:06:01.430771 137620239122432 train.py:138] Starting evaluation\n","I0416 14:06:24.186168 137620239122432 train.py:149] step: 2500, eval_loss: nan\n","I0416 14:07:38.156489 137620239122432 train.py:138] Starting evaluation\n","I0416 14:07:59.986656 137620239122432 train.py:149] step: 2600, eval_loss: inf\n","I0416 14:09:13.701972 137620239122432 train.py:138] Starting evaluation\n","I0416 14:09:36.904698 137620239122432 train.py:149] step: 2700, eval_loss: nan\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/train.py\", line 178, in <module>\n","    app.run(main)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/train.py\", line 27, in main\n","    train(FLAGS.config, FLAGS.workdir,FLAGS.blur_type)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/train.py\", line 127, in train\n","    loss, losses_batch, fwd_steps_batch = train_step_fn(state, batch)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/scripts/losses.py\", line 108, in step_fn\n","    loss, losses_batch, fwd_steps_batch = loss_fn(model, batch)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/scripts/losses.py\", line 74, in loss_fn\n","    diff = model_fn(perturbed_data, fwd_steps)\n","  File \"/content/drive/MyDrive/Colab/diffusion/generative-inverse-heat-dissipation/model_code/utils.py\", line 245, in model_fn\n","    model.train()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2394, in train\n","    module.train(mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2394, in train\n","    module.train(mode)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2394, in train\n","    module.train(mode)\n","  [Previous line repeated 3 more times]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2392, in train\n","    self.training = mode\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1700, in __setattr__\n","    if isinstance(value, Parameter):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/parameter.py\", line 10, in __instancecheck__\n","    isinstance(instance, torch.Tensor) and getattr(instance, '_is_param', False))\n","KeyboardInterrupt\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}